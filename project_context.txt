Project: SeeingwithHand - Collaborative Seeing Sessions Tool

---

Vision:
A web-based platform for documenting, sharing, and reflecting on visual 'seeing sessions' with images. Each session records canvas actions (drawing, mouse, tool changes) and voice narration, stores metadata and user reflection, and enables synchronized replay. Sessions are organized in a gallery and can be shared as standalone pages.

---

Key Features:
- Gallery of images (with metadata: title, caption, source, uploaded_by, upload_date, display_order)
- Each image has multiple 'seeing sessions' (variants)
- Session recording: canvas actions + voice narration (with pause/resume)
- Session naming: auto-incremented per image (e.g., session 0003)
- Survey/reflection page after session, input saved as session metadata
- All data stored in Supabase (canvas, audio, metadata, survey)
- Synchronized replay (animation + audio)
- Public sharing: gallery and standalone session pages
- SVG logo in public/

---

Data Files:
- Images in public/images/
- Metadata in public/images/images.json
- SVG logo in public/

---

UI/UX (per Figma):
- Left panel: image catalogue, scrollable, shows images and session variants
- Right panel: empty on load, shows details on hover, locks on click, shows prepare page before session
- Prepare page: instructions, 'Start Seeing Session' button
- Drawing tool: records actions and audio
- Survey page: reflection input, shows playback/visualization

---

Decisions:
- Use Supabase for all storage
- Session_id: unique, long; session_name: short, auto-incremented per image
- Images centered and scaled to fit fixed canvas proportion
- Modular, independent components

---

To continue work, reference this file for project context and decisions. 

---
END SESSION FLOW: 

After  “Stop Recording” (session) button is pressed:

1. Audio recording (if enabled) automatically ceases.
    
2. A session reflection survey appears.
    
3. The user completes the Ambience Survey.
    
4. Session data and survey responses are stored in the backend.
    
5. The user is redirected to the home page (gallery).
  

Ambience Survey:

1. An animated replay of traces created, superimposing the image (with 2x speed option).
    
2. An audio track of the audio recorded during the session (session-ambiance-audio)
    
3. An eye animation translating the tracing data
    
4. Form collecting: nickname, location, weather indicator, mood indicator, text input “how do you feel”
    
5. A little component: “Additional Context” folder, ux similar to [are.na](http://are.na)’s. This is basically an editable folder in gallery view that has allows uploading file by the user to provide additional ambience or context to their seeing experience. Files supported: text, image, video, url, audio
    

Additional Context folder: (when it is taking input):

1. "Add Note" button: when user clicks, it populates a text block, similar to sticky note, user can add plain text, and hit enter to submit. Submitting creates a note (session-ambience-note) that appears in the folder. Each submitted note creates a text file in the backend.
    
2. "Add Media" button: Clicking this allows users to upload supported documents. Upon submission, the files appear in the folder.
    
3. The uploaded files and session-ambience-note files will be saved along with input collected from the rest of the survey. 
    

4. Submit button
---